{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aQM4xoMkr4B",
        "outputId": "65c18728-836f-4708-f16d-626093dda365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame head after converting 'date' column:\n",
            "        date  temperature  humidity  irradiance  potential  wind_speed\n",
            "0 1950-01-01       22.384    77.513      805.17     4.1294     0.12452\n",
            "1 1950-01-02       22.184    76.513      804.17     4.1194     0.13452\n",
            "2 1950-01-03       22.724    78.124      779.17     3.9913     0.20164\n",
            "3 1950-01-04       23.304    77.783      829.17     4.2474     0.41398\n",
            "4 1950-01-05       23.220    78.819      816.67     4.1834     0.43339\n",
            "\n",
            "DataFrame info after converting 'date' column:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27214 entries, 0 to 27213\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   date         27214 non-null  datetime64[ns]\n",
            " 1   temperature  27214 non-null  float64       \n",
            " 2   humidity     27214 non-null  float64       \n",
            " 3   irradiance   27214 non-null  float64       \n",
            " 4   potential    27214 non-null  float64       \n",
            " 5   wind_speed   27214 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(5)\n",
            "memory usage: 1.2 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Bambili_treated.csv file\n",
        "file_name = \"Bafoussam_treated.csv\"\n",
        "bafoussam_df = pd.read_csv(file_name)\n",
        "\n",
        "# Convert the 'date' column to datetime objects\n",
        "# The format '%Y%m%d' specifies that dates are like 'YYYYMMDD' (e.g., 19500101)\n",
        "bafoussam_df['date'] = pd.to_datetime(bafoussam_df['date'], format='%Y%m%d')\n",
        "\n",
        "print(\"DataFrame head after converting 'date' column:\")\n",
        "print(bafoussam_df.head())\n",
        "print(\"\\nDataFrame info after converting 'date' column:\")\n",
        "print(bafoussam_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Bafoussam dataset\n",
        "# Assuming 'bafoussam_df' is already loaded or you need to load it here\n",
        "# For example, if it's from a CSV:\n",
        "# bafoussam_df = pd.read_csv('your_bafoussam_dataset.csv')\n",
        "# Make sure the 'date' column is in datetime format if you just loaded it\n",
        "# bafoussam_df['date'] = pd.to_datetime(bafoussam_df['date'])\n",
        "\n",
        "# IMPORTANT: You need to load your 'bafoussam_df' DataFrame here.\n",
        "# For example:\n",
        "# bafoussam_df = pd.read_csv(\"path/to/your/Bafoussam_dataset.csv\")\n",
        "# bafoussam_df['date'] = pd.to_datetime(bafoussam_df['date'])\n",
        "\n",
        "# If you want to use a file you've already uploaded, please specify its name.\n",
        "# For demonstration, let's assume 'Bambili_treated.csv' is actually 'Bafoussam_treated.csv' for this example,\n",
        "# or you would load your actual Bafoussam file here.\n",
        "# For now, let's assume 'bafoussam_df' is the DataFrame you are working with.\n",
        "# If you have a file like 'Bafoussam_treated.csv', replace the line below:\n",
        "bafoussam_df = pd.read_csv(\"Bafoussam_treated.csv\") # Placeholder: REPLACE with your actual Bafoussam file\n",
        "bafoussam_df['date'] = pd.to_datetime(bafoussam_df['date'])\n",
        "\n",
        "\n",
        "# Extract various time-based features\n",
        "bafoussam_df['year'] = bafoussam_df['date'].dt.year\n",
        "bafoussam_df['month'] = bafoussam_df['date'].dt.month\n",
        "bafoussam_df['day_of_month'] = bafoussam_df['date'].dt.day\n",
        "bafoussam_df['day_of_week'] = bafoussam_df['date'].dt.dayofweek # Monday=0, Sunday=6\n",
        "bafoussam_df['day_of_year'] = bafoussam_df['date'].dt.dayofyear\n",
        "bafoussam_df['week_of_year'] = bafoussam_df['date'].dt.isocalendar().week.astype(int)\n",
        "bafoussam_df['quarter'] = bafoussam_df['date'].dt.quarter\n",
        "\n",
        "# Add binary flags for start/end of month, quarter, and year\n",
        "bafoussam_df['is_month_start'] = bafoussam_df['date'].dt.is_month_start.astype(int)\n",
        "bafoussam_df['is_month_end'] = bafoussam_df['date'].dt.is_month_end.astype(int)\n",
        "bafoussam_df['is_quarter_start'] = bafoussam_df['date'].dt.is_quarter_start.astype(int)\n",
        "bafoussam_df['is_quarter_end'] = bafoussam_df['date'].dt.is_quarter_end.astype(int)\n",
        "bafoussam_df['is_year_start'] = bafoussam_df['date'].dt.is_year_start.astype(int)\n",
        "bafoussam_df['is_year_end'] = bafoussam_df['date'].dt.is_year_end.astype(int)\n",
        "\n",
        "# Add cyclical features for Month, Day of Year, and Day of Week\n",
        "# Month (1-12)\n",
        "bafoussam_df['month_sin'] = np.sin(2 * np.pi * bafoussam_df['month'] / 12)\n",
        "bafoussam_df['month_cos'] = np.cos(2 * np.pi * bafoussam_df['month'] / 12)\n",
        "\n",
        "# Day of Year (1-366 for leap years)\n",
        "# Use 366 for the cycle to account for leap years, or 365.25 for average\n",
        "bafoussam_df['day_of_year_sin'] = np.sin(2 * np.pi * bafoussam_df['day_of_year'] / 366)\n",
        "bafoussam_df['day_of_year_cos'] = np.cos(2 * np.pi * bafoussam_df['day_of_year'] / 366)\n",
        "\n",
        "# Day of Week (0-6)\n",
        "bafoussam_df['day_of_week_sin'] = np.sin(2 * np.pi * bafoussam_df['day_of_week'] / 7)\n",
        "bafoussam_df['day_of_week_cos'] = np.cos(2 * np.pi * bafoussam_df['day_of_week'] / 7)\n",
        "\n",
        "# Display the first few rows with new features and updated info\n",
        "print(\"\\nDataFrame head with new time-based features:\")\n",
        "print(bafoussam_df.head())\n",
        "print(\"\\nDataFrame info with new time-based features:\")\n",
        "print(bafoussam_df.info())\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_file_name = \"Bafoussam_treated_with_time_features.csv\"\n",
        "bafoussam_df.to_csv(output_file_name, index=False)\n",
        "print(f\"\\nUpdated dataset saved to '{output_file_name}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCZI6DkAl0R6",
        "outputId": "ffa2857a-c574-4100-ca98-2776fba96284"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame head with new time-based features:\n",
            "                           date  temperature  humidity  irradiance  potential  \\\n",
            "0 1970-01-01 00:00:00.019500101       22.384    77.513      805.17     4.1294   \n",
            "1 1970-01-01 00:00:00.019500102       22.184    76.513      804.17     4.1194   \n",
            "2 1970-01-01 00:00:00.019500103       22.724    78.124      779.17     3.9913   \n",
            "3 1970-01-01 00:00:00.019500104       23.304    77.783      829.17     4.2474   \n",
            "4 1970-01-01 00:00:00.019500105       23.220    78.819      816.67     4.1834   \n",
            "\n",
            "   wind_speed  year  month  day_of_month  day_of_week  ...  is_quarter_start  \\\n",
            "0     0.12452  1970      1             1            3  ...                 1   \n",
            "1     0.13452  1970      1             1            3  ...                 1   \n",
            "2     0.20164  1970      1             1            3  ...                 1   \n",
            "3     0.41398  1970      1             1            3  ...                 1   \n",
            "4     0.43339  1970      1             1            3  ...                 1   \n",
            "\n",
            "   is_quarter_end  is_year_start  is_year_end  month_sin  month_cos  \\\n",
            "0               0              1            0        0.5   0.866025   \n",
            "1               0              1            0        0.5   0.866025   \n",
            "2               0              1            0        0.5   0.866025   \n",
            "3               0              1            0        0.5   0.866025   \n",
            "4               0              1            0        0.5   0.866025   \n",
            "\n",
            "   day_of_year_sin  day_of_year_cos  day_of_week_sin  day_of_week_cos  \n",
            "0         0.017166         0.999853         0.433884        -0.900969  \n",
            "1         0.017166         0.999853         0.433884        -0.900969  \n",
            "2         0.017166         0.999853         0.433884        -0.900969  \n",
            "3         0.017166         0.999853         0.433884        -0.900969  \n",
            "4         0.017166         0.999853         0.433884        -0.900969  \n",
            "\n",
            "[5 rows x 25 columns]\n",
            "\n",
            "DataFrame info with new time-based features:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27214 entries, 0 to 27213\n",
            "Data columns (total 25 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   date              27214 non-null  datetime64[ns]\n",
            " 1   temperature       27214 non-null  float64       \n",
            " 2   humidity          27214 non-null  float64       \n",
            " 3   irradiance        27214 non-null  float64       \n",
            " 4   potential         27214 non-null  float64       \n",
            " 5   wind_speed        27214 non-null  float64       \n",
            " 6   year              27214 non-null  int32         \n",
            " 7   month             27214 non-null  int32         \n",
            " 8   day_of_month      27214 non-null  int32         \n",
            " 9   day_of_week       27214 non-null  int32         \n",
            " 10  day_of_year       27214 non-null  int32         \n",
            " 11  week_of_year      27214 non-null  int64         \n",
            " 12  quarter           27214 non-null  int32         \n",
            " 13  is_month_start    27214 non-null  int64         \n",
            " 14  is_month_end      27214 non-null  int64         \n",
            " 15  is_quarter_start  27214 non-null  int64         \n",
            " 16  is_quarter_end    27214 non-null  int64         \n",
            " 17  is_year_start     27214 non-null  int64         \n",
            " 18  is_year_end       27214 non-null  int64         \n",
            " 19  month_sin         27214 non-null  float64       \n",
            " 20  month_cos         27214 non-null  float64       \n",
            " 21  day_of_year_sin   27214 non-null  float64       \n",
            " 22  day_of_year_cos   27214 non-null  float64       \n",
            " 23  day_of_week_sin   27214 non-null  float64       \n",
            " 24  day_of_week_cos   27214 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(11), int32(6), int64(7)\n",
            "memory usage: 4.6 MB\n",
            "None\n",
            "\n",
            "Updated dataset saved to 'Bafoussam_treated_with_time_features.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Load the updated Bambili dataset with time-based features\n",
        "file_name = \"Bafoussam_treated_with_time_features.csv\"\n",
        "bafoussam_df_features = pd.read_csv(file_name)\n",
        "\n",
        "# Display the first few rows and information about the DataFrame to confirm the new features\n",
        "print(\"Bafoussam_treated_with_time_features.csv head:\")\n",
        "print(bafoussam_df_features.head())\n",
        "print(\"\\nBambili_treated_with_time_features.csv info:\")\n",
        "print(bafoussam_df_features.info())\n",
        "\n",
        "# Define the target variable\n",
        "target_column = 'irradiance'\n",
        "\n",
        "# Define features (X) by dropping the 'date' column and the target column\n",
        "# The 'date' column itself is no longer needed as its information is now in the new features.\n",
        "X_bafoussam = bafoussam_df_features.drop(columns=['date', target_column])\n",
        "y_bafoussam = bafoussam_df_features[target_column]\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize RFE with n_features_to_select = 14\n",
        "# The 'step' parameter controls how many features are removed at each iteration.\n",
        "# A step of 1 means one feature is removed at a time.\n",
        "selector = RFE(estimator=estimator, n_features_to_select=14, step=1)\n",
        "\n",
        "# Fit RFE to the Bambili data with the expanded feature set\n",
        "selector.fit(X_bafoussam, y_bafoussam)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features_mask = selector.support_\n",
        "selected_feature_names = X_bafoussam.columns[selected_features_mask].tolist()\n",
        "\n",
        "print(f\"\\nOriginal number of features (excluding 'date' and target): {X_bafoussam.shape[1]}\")\n",
        "print(f\"Selected 14 features for Bambili using RFE: {selected_feature_names}\")\n",
        "\n",
        "# Optionally, you can also get the ranking of features (1 being the most important)\n",
        "feature_ranking = pd.DataFrame({'Feature': X_bafoussam.columns, 'Ranking': selector.ranking_})\n",
        "feature_ranking = feature_ranking.sort_values(by='Ranking')\n",
        "print(\"\\nFeature ranking (1 = selected/most important):\")\n",
        "print(feature_ranking)\n",
        "\n",
        "# Create a DataFrame with only the selected features and the target variable\n",
        "selected_df = bafoussam_df_features[selected_feature_names + [target_column]]\n",
        "\n",
        "# Save the DataFrame with selected features\n",
        "output_file_name_selected = \"Bafoussam_selected_features.csv\"\n",
        "selected_df.to_csv(output_file_name_selected, index=False)\n",
        "print(f\"\\nDataset with selected features saved to '{output_file_name_selected}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv5pc0-XmDPC",
        "outputId": "9f821b30-9717-443e-f596-c8920224e41f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bafoussam_treated_with_time_features.csv head:\n",
            "                            date  temperature  humidity  irradiance  \\\n",
            "0  1970-01-01 00:00:00.019500101       22.384    77.513      805.17   \n",
            "1  1970-01-01 00:00:00.019500102       22.184    76.513      804.17   \n",
            "2  1970-01-01 00:00:00.019500103       22.724    78.124      779.17   \n",
            "3  1970-01-01 00:00:00.019500104       23.304    77.783      829.17   \n",
            "4  1970-01-01 00:00:00.019500105       23.220    78.819      816.67   \n",
            "\n",
            "   potential  wind_speed  year  month  day_of_month  day_of_week  ...  \\\n",
            "0     4.1294     0.12452  1970      1             1            3  ...   \n",
            "1     4.1194     0.13452  1970      1             1            3  ...   \n",
            "2     3.9913     0.20164  1970      1             1            3  ...   \n",
            "3     4.2474     0.41398  1970      1             1            3  ...   \n",
            "4     4.1834     0.43339  1970      1             1            3  ...   \n",
            "\n",
            "   is_quarter_start  is_quarter_end  is_year_start  is_year_end  month_sin  \\\n",
            "0                 1               0              1            0        0.5   \n",
            "1                 1               0              1            0        0.5   \n",
            "2                 1               0              1            0        0.5   \n",
            "3                 1               0              1            0        0.5   \n",
            "4                 1               0              1            0        0.5   \n",
            "\n",
            "   month_cos  day_of_year_sin  day_of_year_cos  day_of_week_sin  \\\n",
            "0   0.866025         0.017166         0.999853         0.433884   \n",
            "1   0.866025         0.017166         0.999853         0.433884   \n",
            "2   0.866025         0.017166         0.999853         0.433884   \n",
            "3   0.866025         0.017166         0.999853         0.433884   \n",
            "4   0.866025         0.017166         0.999853         0.433884   \n",
            "\n",
            "   day_of_week_cos  \n",
            "0        -0.900969  \n",
            "1        -0.900969  \n",
            "2        -0.900969  \n",
            "3        -0.900969  \n",
            "4        -0.900969  \n",
            "\n",
            "[5 rows x 25 columns]\n",
            "\n",
            "Bambili_treated_with_time_features.csv info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27214 entries, 0 to 27213\n",
            "Data columns (total 25 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   date              27214 non-null  object \n",
            " 1   temperature       27214 non-null  float64\n",
            " 2   humidity          27214 non-null  float64\n",
            " 3   irradiance        27214 non-null  float64\n",
            " 4   potential         27214 non-null  float64\n",
            " 5   wind_speed        27214 non-null  float64\n",
            " 6   year              27214 non-null  int64  \n",
            " 7   month             27214 non-null  int64  \n",
            " 8   day_of_month      27214 non-null  int64  \n",
            " 9   day_of_week       27214 non-null  int64  \n",
            " 10  day_of_year       27214 non-null  int64  \n",
            " 11  week_of_year      27214 non-null  int64  \n",
            " 12  quarter           27214 non-null  int64  \n",
            " 13  is_month_start    27214 non-null  int64  \n",
            " 14  is_month_end      27214 non-null  int64  \n",
            " 15  is_quarter_start  27214 non-null  int64  \n",
            " 16  is_quarter_end    27214 non-null  int64  \n",
            " 17  is_year_start     27214 non-null  int64  \n",
            " 18  is_year_end       27214 non-null  int64  \n",
            " 19  month_sin         27214 non-null  float64\n",
            " 20  month_cos         27214 non-null  float64\n",
            " 21  day_of_year_sin   27214 non-null  float64\n",
            " 22  day_of_year_cos   27214 non-null  float64\n",
            " 23  day_of_week_sin   27214 non-null  float64\n",
            " 24  day_of_week_cos   27214 non-null  float64\n",
            "dtypes: float64(11), int64(13), object(1)\n",
            "memory usage: 5.2+ MB\n",
            "None\n",
            "\n",
            "Original number of features (excluding 'date' and target): 23\n",
            "Selected 14 features for Bambili using RFE: ['temperature', 'humidity', 'potential', 'wind_speed', 'year', 'month', 'day_of_month', 'is_year_end', 'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week_sin', 'day_of_week_cos']\n",
            "\n",
            "Feature ranking (1 = selected/most important):\n",
            "             Feature  Ranking\n",
            "0        temperature        1\n",
            "1           humidity        1\n",
            "2          potential        1\n",
            "3         wind_speed        1\n",
            "4               year        1\n",
            "5              month        1\n",
            "6       day_of_month        1\n",
            "16       is_year_end        1\n",
            "19   day_of_year_sin        1\n",
            "22   day_of_week_cos        1\n",
            "21   day_of_week_sin        1\n",
            "20   day_of_year_cos        1\n",
            "17         month_sin        1\n",
            "18         month_cos        1\n",
            "15     is_year_start        2\n",
            "14    is_quarter_end        3\n",
            "13  is_quarter_start        4\n",
            "12      is_month_end        5\n",
            "11    is_month_start        6\n",
            "10           quarter        7\n",
            "9       week_of_year        8\n",
            "8        day_of_year        9\n",
            "7        day_of_week       10\n",
            "\n",
            "Dataset with selected features saved to 'Bafoussam_selected_features.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Load the dataset with selected features\n",
        "file_name = \"Bafoussam_selected_features.csv\"\n",
        "bafoussam_df_selected = pd.read_csv(file_name)\n",
        "\n",
        "print(\"DataFrame head with selected features:\")\n",
        "print(bafoussam_df_selected.head())\n",
        "print(\"\\nDataFrame info with selected features:\")\n",
        "print(bafoussam_df_selected.info())\n",
        "\n",
        "# Define the target variable\n",
        "target_column = 'irradiance'\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = bafoussam_df_selected.drop(columns=[target_column])\n",
        "y = bafoussam_df_selected[target_column]\n",
        "\n",
        "print(f\"\\nFeatures (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "\n",
        "# Prepare for 10-fold cross-validation\n",
        "# The paper mentions \"tenfold cross validation techniques\" for model development and evaluation.\n",
        "# KFold is a good way to generate the indices for these folds.\n",
        "n_splits = 10 # As per \"tenfold cross validation\"\n",
        "\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"\\nPreparing for {n_splits}-fold cross-validation:\")\n",
        "print(\"Iterating through folds to show the split indices:\")\n",
        "\n",
        "fold_count = 0\n",
        "for train_index, test_index in kf.split(X):\n",
        "    fold_count += 1\n",
        "    # You would typically use these indices to get your train and test sets for each fold\n",
        "    # X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    # y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    print(f\"  Fold {fold_count}:\")\n",
        "    print(f\"    Train set size: {len(train_index)} samples\")\n",
        "    print(f\"    Test set size: {len(test_index)} samples\")\n",
        "    # For brevity, we are not printing the actual data, just the sizes.\n",
        "    if fold_count >= 3: # Print only first 3 folds to avoid too much output\n",
        "        print(\"  ...\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nData successfully prepared for {n_splits}-fold cross-validation.\")\n",
        "print(\"Each iteration of the KFold object provides indices to split your data into training and testing sets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTPrYwuooR1u",
        "outputId": "59bd0ba0-c555-4ad9-890f-ffc1e8260c42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame head with selected features:\n",
            "   temperature  humidity  potential  wind_speed  year  month  day_of_month  \\\n",
            "0       22.384    77.513     4.1294     0.12452  1970      1             1   \n",
            "1       22.184    76.513     4.1194     0.13452  1970      1             1   \n",
            "2       22.724    78.124     3.9913     0.20164  1970      1             1   \n",
            "3       23.304    77.783     4.2474     0.41398  1970      1             1   \n",
            "4       23.220    78.819     4.1834     0.43339  1970      1             1   \n",
            "\n",
            "   is_year_end  month_sin  month_cos  day_of_year_sin  day_of_year_cos  \\\n",
            "0            0        0.5   0.866025         0.017166         0.999853   \n",
            "1            0        0.5   0.866025         0.017166         0.999853   \n",
            "2            0        0.5   0.866025         0.017166         0.999853   \n",
            "3            0        0.5   0.866025         0.017166         0.999853   \n",
            "4            0        0.5   0.866025         0.017166         0.999853   \n",
            "\n",
            "   day_of_week_sin  day_of_week_cos  irradiance  \n",
            "0         0.433884        -0.900969      805.17  \n",
            "1         0.433884        -0.900969      804.17  \n",
            "2         0.433884        -0.900969      779.17  \n",
            "3         0.433884        -0.900969      829.17  \n",
            "4         0.433884        -0.900969      816.67  \n",
            "\n",
            "DataFrame info with selected features:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27214 entries, 0 to 27213\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   temperature      27214 non-null  float64\n",
            " 1   humidity         27214 non-null  float64\n",
            " 2   potential        27214 non-null  float64\n",
            " 3   wind_speed       27214 non-null  float64\n",
            " 4   year             27214 non-null  int64  \n",
            " 5   month            27214 non-null  int64  \n",
            " 6   day_of_month     27214 non-null  int64  \n",
            " 7   is_year_end      27214 non-null  int64  \n",
            " 8   month_sin        27214 non-null  float64\n",
            " 9   month_cos        27214 non-null  float64\n",
            " 10  day_of_year_sin  27214 non-null  float64\n",
            " 11  day_of_year_cos  27214 non-null  float64\n",
            " 12  day_of_week_sin  27214 non-null  float64\n",
            " 13  day_of_week_cos  27214 non-null  float64\n",
            " 14  irradiance       27214 non-null  float64\n",
            "dtypes: float64(11), int64(4)\n",
            "memory usage: 3.1 MB\n",
            "None\n",
            "\n",
            "Features (X) shape: (27214, 14)\n",
            "Target (y) shape: (27214,)\n",
            "\n",
            "Preparing for 10-fold cross-validation:\n",
            "Iterating through folds to show the split indices:\n",
            "  Fold 1:\n",
            "    Train set size: 24492 samples\n",
            "    Test set size: 2722 samples\n",
            "  Fold 2:\n",
            "    Train set size: 24492 samples\n",
            "    Test set size: 2722 samples\n",
            "  Fold 3:\n",
            "    Train set size: 24492 samples\n",
            "    Test set size: 2722 samples\n",
            "  ...\n",
            "\n",
            "Data successfully prepared for 10-fold cross-validation.\n",
            "Each iteration of the KFold object provides indices to split your data into training and testing sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Load the dataset with selected features\n",
        "file_name = \"Bafoussam_selected_features.csv\"\n",
        "bafoussam_df_selected = pd.read_csv(file_name)\n",
        "\n",
        "# Define the target variable\n",
        "target_column = 'irradiance'\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = bafoussam_df_selected.drop(columns=[target_column])\n",
        "y = bafoussam_df_selected[target_column]\n",
        "\n",
        "# Normalize features and target (important for neural networks)\n",
        "# Use MinMaxScaler for features (X) and target (y) separately\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "# Reshape y to 2D array for scaler (it expects 2D input)\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "print(f\"X_scaled shape: {X_scaled.shape}\")\n",
        "print(f\"y_scaled shape: {y_scaled.shape}\")\n",
        "\n",
        "# Function to create sequences for CNN-LSTM\n",
        "# n_timesteps: how many past days/observations to use for prediction\n",
        "def create_sequences(X, y, n_timesteps):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - n_timesteps):\n",
        "        # Features from t to t + n_timesteps - 1\n",
        "        Xs.append(X[i:(i + n_timesteps)])\n",
        "        # Target at t + n_timesteps\n",
        "        ys.append(y[i + n_timesteps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# Define the number of timesteps. This is a hyperparameter!\n",
        "# Let's start with 7 timesteps (using the past 7 days to predict the next day).\n",
        "n_timesteps = 7\n",
        "print(f\"\\nCreating sequences with {n_timesteps} timesteps...\")\n",
        "\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, n_timesteps)\n",
        "\n",
        "print(f\"Shape of X_seq (samples, timesteps, features): {X_seq.shape}\")\n",
        "print(f\"Shape of y_seq (samples, target): {y_seq.shape}\")\n",
        "\n",
        "# Prepare for 10-fold cross-validation (using the sequential data)\n",
        "n_splits = 10\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# This loop will now be used for actual model training in the next steps\n",
        "# print(f\"\\nSample KFold split with sequential data:\")\n",
        "# fold_count = 0\n",
        "# for train_index, test_index in kf.split(X_seq):\n",
        "#     fold_count += 1\n",
        "#     print(f\"  Fold {fold_count}: Train samples: {len(train_index)}, Test samples: {len(test_index)}\")\n",
        "#     if fold_count >= 1: # Just show one example\n",
        "#         break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OcgfByNpBc0",
        "outputId": "281ca85c-a8a0-4bbe-e1cc-4cce143e74a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_scaled shape: (27214, 14)\n",
            "y_scaled shape: (27214, 1)\n",
            "\n",
            "Creating sequences with 7 timesteps...\n",
            "Shape of X_seq (samples, timesteps, features): (27207, 7, 14)\n",
            "Shape of y_seq (samples, target): (27207, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam # A common optimizer\n",
        "\n",
        "# --- Model Definition ---\n",
        "\n",
        "# Define the number of features (columns in X_seq, which is the last dimension of X_seq.shape)\n",
        "n_features = X_seq.shape[2] # Should be 14\n",
        "\n",
        "# Define the CNN-SLSTM model\n",
        "def build_cnn_slstm_model(n_timesteps, n_features,\n",
        "                          filters=64, kernel_size=2, pool_size=2,\n",
        "                          lstm_units_1=50, lstm_units_2=50,\n",
        "                          dense_units_1=25, dense_units_2=10): # Added a second dense layer as per description\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # CNN Part\n",
        "    # Conv1D processes sequences (timesteps, features)\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu',\n",
        "                     input_shape=(n_timesteps, n_features)))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "\n",
        "    # Flatten the output of the CNN to feed into the LSTM.\n",
        "    # The LSTM expects a 2D input (samples, features) after processing a sequence,\n",
        "    # or a 3D input if it processes a sequence of sequences.\n",
        "    # Given Conv1D and MaxPooling reduce the timesteps, a flatten is typical if LSTM follows\n",
        "    # and processes the reduced sequence as a feature vector per sample.\n",
        "    # However, if LSTM is meant to continue processing a sequence, the Conv1D's output\n",
        "    # (after pooling) should be directly fed without flatten if its output shape is (batch, new_timesteps, filters).\n",
        "    # Let's assume the CNN is feature extraction over the sequence, and the LSTM operates on these processed sequences.\n",
        "    # If MaxPooling1D significantly reduces timesteps, the LSTM might expect the output of CNN to still be sequential.\n",
        "    # A common design is to feed the output of MaxPooling1D directly to LSTM.\n",
        "    # Let's verify the shape transition:\n",
        "    # (None, n_timesteps, n_features) -> Conv1D -> (None, n_timesteps - kernel_size + 1, filters) -> MaxPooling1D -> (None, (n_timesteps - kernel_size + 1) // pool_size, filters)\n",
        "    # This shape is compatible with LSTM.\n",
        "\n",
        "    # Stacked LSTM Part\n",
        "    # First LSTM layer: return_sequences=True to pass the sequence to the next LSTM layer\n",
        "    model.add(LSTM(units=lstm_units_1, activation='relu', return_sequences=True))\n",
        "    # Second LSTM layer: No return_sequences=True as it's the last LSTM before dense layers\n",
        "    model.add(LSTM(units=lstm_units_2, activation='relu'))\n",
        "\n",
        "    # Dense (Fully Connected) Layers as per paper (two dense layers)\n",
        "    model.add(Dense(units=dense_units_1, activation='relu'))\n",
        "    model.add(Dense(units=dense_units_2, activation='relu')) # Added a second dense layer\n",
        "\n",
        "    # Output Layer for Regression\n",
        "    model.add(Dense(units=1, activation='linear')) # Linear activation for regression output\n",
        "\n",
        "    # Compile the model\n",
        "    # 'optimizer': Adam is a popular choice.\n",
        "    # 'loss': 'mse' (Mean Squared Error) is common for regression tasks.\n",
        "    model.compile(optimizer=Adam(), loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build an instance of the model to see its summary\n",
        "# These are placeholder values for hyperparameters, which SMO would optimize later.\n",
        "model = build_cnn_slstm_model(n_timesteps=n_timesteps, n_features=n_features,\n",
        "                              filters=64, kernel_size=2, pool_size=2,\n",
        "                              lstm_units_1=50, lstm_units_2=50,\n",
        "                              dense_units_1=25, dense_units_2=10)\n",
        "\n",
        "print(\"\\n--- CNN-SLSTM Model Summary ---\")\n",
        "model.summary()\n",
        "\n",
        "# You can save the model architecture for later if needed (optional)\n",
        "# model.save('cnn_slstm_architecture.h5') # Saves structure, weights, and optimizer state\n",
        "print(\"\\nCNN-SLSTM model architecture defined successfully.\")\n",
        "print(\"The next step would involve training this model using the K-Fold splits and optimizing hyperparameters with SMO.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "4j6q6fAqpkC4",
        "outputId": "c3a002de-1656-4cdf-e646-e5bc6ad6fd1e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CNN-SLSTM Model Summary ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m1,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m23,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m260\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,602\u001b[0m (182.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,602</span> (182.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,602\u001b[0m (182.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,602</span> (182.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN-SLSTM model architecture defined successfully.\n",
            "The next step would involve training this model using the K-Fold splits and optimizing hyperparameters with SMO.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPvdoCiRp25H",
        "outputId": "649f139b-499e-40e7-f908-ab5a24abb524"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.5.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import Bayesian Optimization library\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "\n",
        "# Suppress TensorFlow warnings for cleaner output during optimization\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# --- 1. Data Preparation ---\n",
        "# Load the dataset with selected features\n",
        "file_name = \"Bafoussam_selected_features.csv\"\n",
        "bafoussam_df_selected = pd.read_csv(file_name)\n",
        "\n",
        "# Define the target variable\n",
        "target_column = 'irradiance'\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X_raw = bafoussam_df_selected.drop(columns=[target_column])\n",
        "y_raw = bafoussam_df_selected[target_column]\n",
        "\n",
        "# Normalize features and target\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X_raw)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(y_raw.values.reshape(-1, 1))\n",
        "\n",
        "# Function to create sequences for CNN-LSTM\n",
        "def create_sequences(X, y, n_timesteps):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - n_timesteps):\n",
        "        Xs.append(X[i:(i + n_timesteps)])\n",
        "        ys.append(y[i + n_timesteps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# Get the number of features (columns in X_raw)\n",
        "n_features = X_raw.shape[1]\n",
        "\n",
        "# --- 2. CNN-SLSTM Model Definition Function ---\n",
        "def build_cnn_slstm_model(n_timesteps_param, n_features_param,\n",
        "                          filters_param, kernel_size_param,\n",
        "                          lstm_units_1_param, lstm_units_2_param,\n",
        "                          dense_units_1_param, dense_units_2_param,\n",
        "                          learning_rate_param, fixed_pool_size=2):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters_param, kernel_size=(kernel_size_param,), activation='relu',\n",
        "                     input_shape=(n_timesteps_param, n_features_param)))\n",
        "    model.add(MaxPooling1D(pool_size=fixed_pool_size))\n",
        "    model.add(LSTM(units=int(lstm_units_1_param), activation='relu', return_sequences=True))\n",
        "    model.add(LSTM(units=int(lstm_units_2_param), activation='relu'))\n",
        "    model.add(Dense(units=dense_units_1_param, activation='relu'))\n",
        "    model.add(Dense(units=dense_units_2_param, activation='relu'))\n",
        "    model.add(Dense(units=1, activation='linear')) # Output layer for regression\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate_param)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# --- 3. Define the Search Space for Hyperparameters ---\n",
        "space = [\n",
        "    Integer(3, 10, name='n_timesteps'),        # Number of past days to consider (sequence length)\n",
        "    Integer(32, 128, name='filters'),          # Number of filters in Conv1D\n",
        "    Integer(2, 3, name='kernel_size'),         # Kernel size for Conv1D\n",
        "    Integer(32, 100, name='lstm_units_1'),     # Units in first LSTM layer\n",
        "    Integer(32, 100, name='lstm_units_2'),     # Units in second LSTM layer\n",
        "    Integer(10, 50, name='dense_units_1'),     # Units in first Dense layer\n",
        "    Integer(5, 20, name='dense_units_2'),      # Units in second Dense layer\n",
        "    Real(1e-4, 1e-2, \"log-uniform\", name='learning_rate'), # Adam optimizer learning rate\n",
        "    Integer(50, 200, name='epochs'),           # Number of training epochs per fold\n",
        "    Integer(16, 64, name='batch_size', prior='log-uniform') # Batch size for training (often powers of 2)\n",
        "]\n",
        "\n",
        "# --- 4. Objective Function for Bayesian Optimization ---\n",
        "@use_named_args(space)\n",
        "def objective_function(**hyperparameters):\n",
        "    # Extract hyperparameters from the input dictionary\n",
        "    n_timesteps = hyperparameters['n_timesteps']\n",
        "    filters = hyperparameters['filters']\n",
        "    kernel_size = hyperparameters['kernel_size']\n",
        "    lstm_units_1 = hyperparameters['lstm_units_1']\n",
        "    lstm_units_2 = hyperparameters['lstm_units_2']\n",
        "    dense_units_1 = hyperparameters['dense_units_1']\n",
        "    dense_units_2 = hyperparameters['dense_units_2']\n",
        "    learning_rate = hyperparameters['learning_rate']\n",
        "    epochs = hyperparameters['epochs']\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "\n",
        "    # Fixed pool_size value\n",
        "    fixed_pool_size = 2\n",
        "\n",
        "    print(f\"\\n--- Evaluating Trial ---\")\n",
        "    print(f\"Hyperparams: n_timesteps={n_timesteps}, filters={filters}, kernel_size={kernel_size}, \"\n",
        "          f\"pool_size={fixed_pool_size}, lstm_units_1={lstm_units_1}, lstm_units_2={lstm_units_2}, \"\n",
        "          f\"dense_units_1={dense_units_1}, dense_units_2={dense_units_2}, \"\n",
        "          f\"lr={learning_rate:.6f}, epochs={epochs}, batch_size={batch_size}\")\n",
        "\n",
        "    # --- NEW CHECK: Ensure Conv1D output is large enough for MaxPooling1D ---\n",
        "    conv1d_output_length = n_timesteps - kernel_size + 1\n",
        "    if conv1d_output_length < fixed_pool_size:\n",
        "        print(f\"  SKIPPING: Invalid combination (n_timesteps={n_timesteps}, kernel_size={kernel_size}). \"\n",
        "              f\"Conv1D output length ({conv1d_output_length}) is too small for MaxPooling1D (pool_size={fixed_pool_size}).\")\n",
        "        return 1e9 # Penalize this invalid combination with a very high error\n",
        "\n",
        "    # Re-create sequences based on the current n_timesteps hyperparameter\n",
        "    try:\n",
        "        current_X_seq, current_y_seq = create_sequences(X_scaled, y_scaled, n_timesteps)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error creating sequences for n_timesteps={n_timesteps}: {e}\")\n",
        "        return 1e9 # Return a very high error to penalize invalid n_timesteps values\n",
        "\n",
        "    if current_X_seq.shape[0] == 0: # Handle cases where n_timesteps is too large for data\n",
        "        print(f\"Not enough data for n_timesteps={n_timesteps}. Returning high error.\")\n",
        "        return 1e9\n",
        "\n",
        "    # Prepare for 10-fold cross-validation\n",
        "    n_splits = 10\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_mses = [] # To store MSE for each fold\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(kf.split(current_X_seq)):\n",
        "        # Clear Keras session for each fold to prevent memory issues and model state leakage\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        # Build the model with the current hyperparameters and fixed pool_size\n",
        "        model = build_cnn_slstm_model(n_timesteps_param=n_timesteps,\n",
        "                                      n_features_param=n_features,\n",
        "                                      filters_param=filters,\n",
        "                                      kernel_size_param=kernel_size,\n",
        "                                      lstm_units_1_param=lstm_units_1,\n",
        "                                      lstm_units_2_param=lstm_units_2,\n",
        "                                      dense_units_1_param=dense_units_1,\n",
        "                                      dense_units_2_param=dense_units_2,\n",
        "                                      learning_rate_param=learning_rate,\n",
        "                                      fixed_pool_size=fixed_pool_size) # Pass fixed pool_size\n",
        "\n",
        "        # Split data for the current fold\n",
        "        X_train, X_val = current_X_seq[train_index], current_X_seq[val_index]\n",
        "        y_train, y_val = current_y_seq[train_index], current_y_seq[val_index]\n",
        "\n",
        "        # Fit the model for the current fold\n",
        "        try:\n",
        "            model.fit(X_train, y_train,\n",
        "                      epochs=epochs,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      verbose=0) # Set verbose to 0 to suppress training output per epoch\n",
        "\n",
        "            # Evaluate the model on the validation set of the current fold\n",
        "            mse = model.evaluate(X_val, y_val, verbose=0)\n",
        "            fold_mses.append(mse)\n",
        "            print(f\"  Fold {fold+1} MSE: {mse:.4f}\")\n",
        "        except tf.errors.InvalidArgumentError as e:\n",
        "            print(f\"TensorFlow Invalid Argument Error during training/evaluation in fold {fold+1}: {e}\")\n",
        "            fold_mses.append(1e9) # Penalize with high error\n",
        "        except Exception as e:\n",
        "            print(f\"General error during training/evaluation in fold {fold+1}: {e}\")\n",
        "            fold_mses.append(1e9) # Penalize with high error\n",
        "\n",
        "    # Calculate the average MSE across all folds\n",
        "    average_mse = np.mean(fold_mses)\n",
        "    print(f\"Average MSE for this set of hyperparameters: {average_mse:.4f}\")\n",
        "\n",
        "    # Return the average MSE (skopt minimizes this value)\n",
        "    return average_mse\n",
        "\n",
        "# --- 5. Run Bayesian Optimization ---\n",
        "print(\"\\n--- Starting Bayesian Optimization (This may take a while) ---\")\n",
        "results = gp_minimize(\n",
        "    func=objective_function,\n",
        "    dimensions=space,\n",
        "    n_calls=20, # Recommend starting small, then increase for production\n",
        "    n_random_starts=5,\n",
        "    random_state=42,\n",
        "    verbose=True,\n",
        "    n_jobs=1 # Set to 1 to avoid potential issues with TensorFlow multi-threading if not carefully managed\n",
        ")\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"\\n--- Bayesian Optimization Results ---\")\n",
        "print(f\"Best validation MSE found: {results.fun:.4f}\")\n",
        "print(\"Best hyperparameters:\")\n",
        "best_hyperparameters = {dim.name: value for dim, value in zip(space, results.x)}\n",
        "print(best_hyperparameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoqAhkV4p8EJ",
        "outputId": "e546184f-3c0c-4be9-8ed4-d8860f0064d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Bayesian Optimization (This may take a while) ---\n",
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "\n",
            "--- Evaluating Trial ---\n",
            "Hyperparams: n_timesteps=9, filters=50, kernel_size=3, pool_size=2, lstm_units_1=73, lstm_units_2=62, dense_units_1=14, dense_units_2=12, lr=0.000465, epochs=71, batch_size=39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K88AwXt8qaM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}